Announcements
------------

* Thanks for complete lecture schedule. Let's schedule a meeting 1 week before
  your lecture. I often have time in the afternoon before class, but if that 
  doesn't work for you, let me know when you are available.

* Ernest is first up on Monday. Read TAPL chapter 5 and send questions to
  #6700 slack channel so that he can see them.

* Wednesday starts three lectures on Agda. Install Agda on your computer
  before then, but I don't expect you to have any experience with it.

* Next goal: identify projects. Let me know if you want to chat.

* Harry: you know what to do.

Church Rosser Theorem
---------------------
[Wednesday]

* More questions about Church Rosser proof

* Discuss variants and extensions
   CR for normalizing languages
   beta-eta conversion

* Overview of mechanization 
  (more advanced uses of locally nameless)


Lemma 3.2.6 (parallel reduction satisfies diamond property)

* I understand (from Coq’s point of view) how to get the two subcases in case
  2 of proof 3.2.6. However, I don’t really understand how can we get those
  two cases from the lemma 3.2.5. Can you please explain this part?

* What motivates Barendregt's approach to proving CR? Is there a more naive
  approach that fails? I'm a little confused by Lemma 3.2.7, it refers to a
  fact that is unproven and is not obvious to me.

* Comparing Barendregt & Selinger’s proofs of the Church-Rosser Theorem, both
  authors initially define parallel reduction & show that it satisfies
  substitution properties. However, after establishing this, Selinger’s proof
  seems to diverge from Barendregt's. Selinger defines the “maximum parallel
  one step reduction” — he then shows that this satisfies the diamond
  property, and this seems to be sufficient for Selinger to prove the
  theorem. On the other hand, Barendregt needed to prove that β_reduction is a
  superset of the transitive closure of parallel reduction (lemma 3.2.7).  Are
  both authors essentially doing the same thing in their proofs, or is one
  proof simpler than the other (in terms of requiring less machinery)?


Extensions and related results

Eta-equivalence / BetaEta-equivalence
------------------------------------

* How extensible this representation is for proving the Church Rosser theorem
  for eta reduction and beta-eta reduction.

* Theorem 15.2 seems to imply a very convenient algorithm for checking
  confluence under beta-eta reduction. Eta-reduction can be delayed on either
  side of the term until necessary. I wonder if the same theorem holds with
  eta-rules for other data types such as products or unit.
  
* Would changing the order of beta and eta in the postponement of eta-reduction 
  theorem in 3.4 make the theorem no longer true?

* What is the significance of eta to Barendregt and why is it viewed as a
  contraction? It makes more sense as an expansion to me. (Perhaps related, I
  don't understand what it means to "axiomatize provable equality in the
  extensional lambda calculus".)

ANSWER: this is a remark about a discussion from 2.1.

The extensional lambda calculus is beta-conversion plus this rule, called 
extensionality:

          M x = N x
       x not in fv M, N
      ------------------- ext
          M = N
          
Then B shows Theorem (2.1.29) (Curry)
  
    beta-equivalence + ext is the same as beta-eta equivalence

And Theorem (2.1.50) that says that beta-eta equivalence is maximally
consistent in the following way.
    
    If M and N have a normal form, then either M is beta-eta equivalent to N 
    or the theory of beta-eta-equivalence plus M = N is inconsistent.


Other extensions
----------------

* Can you define a version of parallel reduction with a value restriction? Would 
  this rule break the diamond property?

     a => (\x . a')
     b => b'
     Value b'
     -----------------------------------------------
     a b => a' {b' x}


* I know the Church Rosser theorem does not apply to effectful languages
  because the order of effects. Has there been any attempt that you know of to
  formalize a generalization of Church Rosser that does apply?

* Suppose you wanted to prove Church Rosser for a language with more advanced
  features, for example CIC. Does the proof look largely similar?
     
* What kinds of things (besides effects) can break Church-Rosser or 
  Confluence more generally?
  
Weak CR
------
  
* I get the difference in the definition between CR and weak CR, but I don’t
  think I understand the difference of them in terms of application. Can you
  please give some examples on when the two will be different, either
  graphically, or terms?

* Can you please explain how we get the two graphs in 3.1.25? I get the SN
  part, but I don’t get how WCR is being used.
  
* Can you give some more intuition behind 3.1.25 (SN /\ WCR => CR)? Also, I'm
  having trouble figuring out how to interpret the diagrams.

Other
-----

* For today’s class, can we go over the definition of solvable? It looks like
  it uses notation from earlier chapters so I’m having trouble parsing it.

ANSWER: solvability is introduced in chapter 2. It is defined as 

   M is solvable iff there exists N1 .. Nn such that M N1 ... Nn =beta \x.x

it is also stated that terms are solvable iff they have a head normal form.
I'm not planning to cover solvability in class tomorrow --- I want to focus on
the other parts of the chapter.


